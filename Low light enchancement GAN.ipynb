{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"wVHZVny25Cm5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dataset loading"],"metadata":{"id":"giwaHRSfnYWn"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"SQgfs-AI0g_0","executionInfo":{"status":"ok","timestamp":1673722060937,"user_tz":-120,"elapsed":1954,"user":{"displayName":"Catalin","userId":"16988798672554540152"}}},"outputs":[],"source":["# Assumes dataset contains images of shape 512x512x3 containing on the first 256 width pixels the low light image and on the other 256 width pixels the high light image\n","from PIL import Image\n","import torch.utils.data as data\n","import os\n","import random\n","\n","\n","class DatasetFromFolder(data.Dataset):\n","    def __init__(self, image_dir, subfolder='train', direction='AtoB', transform=None, resize_scale=None, crop_size=None, fliplr=False):\n","        super(DatasetFromFolder, self).__init__()\n","        self.input_path = os.path.join(image_dir, subfolder)\n","        self.image_filenames = [x for x in sorted(os.listdir(self.input_path))]\n","        self.direction = direction\n","        self.transform = transform\n","        self.resize_scale = resize_scale\n","        self.crop_size = crop_size\n","        self.fliplr = fliplr\n","\n","    def __getitem__(self, index):\n","        # Load Image\n","        img_fn = os.path.join(self.input_path, self.image_filenames[index])\n","        img = Image.open(img_fn)\n","        if self.direction == 'AtoB': # we will train the model to generate from low light to high light images\n","            input = img.crop((0, 0, img.width // 2, img.height))\n","            target = img.crop((img.width // 2, 0, img.width, img.height))\n","        elif self.direction == 'BtoA': # training from high light to low light images\n","            input = img.crop((img.width // 2, 0, img.width, img.height))\n","            target = img.crop((0, 0, img.width // 2, img.height))\n","\n","        # preprocessing\n","        if self.resize_scale:\n","            input = input.resize((self.resize_scale, self.resize_scale), Image.BILINEAR)\n","            target = target.resize((self.resize_scale, self.resize_scale), Image.BILINEAR)\n","\n","        if self.crop_size:\n","            x = random.randint(0, self.resize_scale - self.crop_size + 1)\n","            y = random.randint(0, self.resize_scale - self.crop_size + 1)\n","            input = input.crop((x, y, x + self.crop_size, y + self.crop_size))\n","            target = target.crop((x, y, x + self.crop_size, y + self.crop_size))\n","        if self.fliplr:\n","            if random.random() < 0.5:\n","                input = input.transpose(Image.FLIP_LEFT_RIGHT)\n","                target = target.transpose(Image.FLIP_LEFT_RIGHT)\n","\n","        if self.transform is not None:\n","            input = self.transform(input)\n","            target = self.transform(target)\n","\n","        return input, target\n","\n","    def __len__(self):\n","        return len(self.image_filenames)"]},{"cell_type":"markdown","source":["Plotting helper functions"],"metadata":{"id":"sFDtjfrnnUlv"}},{"cell_type":"code","source":["import torch\n","from torch.autograd import Variable\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","\n","def to_var(x):\n","    if torch.cuda.is_available():\n","        x = x.cuda()\n","    return Variable(x)\n","\n","\n","# De-normalization\n","def denorm(x):\n","    out = (x + 1) / 2\n","    return out.clamp(0, 1)\n","\n","\n","# Plot losses\n","def plot_loss(d_losses, g_losses, num_epochs, save=False, save_dir='results/', show=False):\n","    fig, ax = plt.subplots()\n","    ax.set_xlim(0, num_epochs)\n","    ax.set_ylim(0, max(np.max(g_losses), np.max(d_losses))*1.1)\n","    plt.xlabel('# of Epochs')\n","    plt.ylabel('Loss values')\n","    plt.plot(d_losses, label='Discriminator')\n","    plt.plot(g_losses, label='Generator')\n","    plt.legend()\n","\n","    # save figure\n","    if save:\n","        if not os.path.exists(save_dir):\n","            os.mkdir(save_dir)\n","        save_fn = save_dir + 'Loss_values_epoch_{:d}'.format(num_epochs) + '.png'\n","        plt.savefig(save_fn)\n","\n","    if show:\n","        plt.show()\n","    else:\n","        plt.close()\n","\n","\n","def plot_test_result(input, target, gen_image, epoch, training=True, save=False, save_dir='results/', show=False, fig_size=(5, 5)):\n","    if not training:\n","        fig_size = (input.size(2) * 3 / 100, input.size(3)/100)\n","\n","    fig, axes = plt.subplots(1, 3, figsize=fig_size)\n","    imgs = [input, gen_image, target]\n","    for ax, img in zip(axes.flatten(), imgs):\n","        ax.axis('off')\n","        # Scale to 0-255\n","        img = (((img[0] - img[0].min()) * 255) / (img[0].max() - img[0].min())).numpy().transpose(1, 2, 0).astype(np.uint8)\n","        ax.imshow(img, cmap=None, aspect='equal')\n","    plt.subplots_adjust(wspace=0, hspace=0)\n","\n","    if training:\n","        title = 'Epoch {0}'.format(epoch + 1)\n","        fig.text(0.5, 0.04, title, ha='center')\n","\n","    # save figure\n","    if save:\n","        if not os.path.exists(save_dir):\n","            os.mkdir(save_dir)\n","        if training:\n","            save_fn = save_dir + 'Result_epoch_{:d}'.format(epoch+1) + '.png'\n","        else:\n","            save_fn = save_dir + 'Test_result_{:d}'.format(epoch+1) + '.png'\n","            fig.subplots_adjust(bottom=0)\n","            fig.subplots_adjust(top=1)\n","            fig.subplots_adjust(right=1)\n","            fig.subplots_adjust(left=0)\n","        plt.savefig(save_fn)\n","\n","    if show:\n","        plt.show()\n","    else:\n","        plt.close()\n"],"metadata":{"id":"CAmtuuUT0us5","executionInfo":{"status":"ok","timestamp":1673722063557,"user_tz":-120,"elapsed":3,"user":{"displayName":"Catalin","userId":"16988798672554540152"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Generator & Discriminator definitions"],"metadata":{"id":"FO3_paDynQDB"}},{"cell_type":"code","source":["import torch\n","\n","\n","class ConvBlock(torch.nn.Module):\n","    def __init__(self, input_size, output_size, kernel_size=4, stride=2, padding=1, activation=True, batch_norm=True):\n","        super(ConvBlock, self).__init__()\n","        self.conv = torch.nn.Conv2d(input_size, output_size, kernel_size, stride, padding)\n","        self.activation = activation\n","        self.lrelu = torch.nn.LeakyReLU(0.2, True)\n","        self.batch_norm = batch_norm\n","        self.bn = torch.nn.BatchNorm2d(output_size)\n","\n","    def forward(self, x):\n","        if self.activation:\n","            out = self.conv(self.lrelu(x))\n","        else:\n","            out = self.conv(x)\n","\n","        if self.batch_norm:\n","            return self.bn(out)\n","        else:\n","            return out\n","\n","\n","class DeconvBlock(torch.nn.Module):\n","    def __init__(self, input_size, output_size, kernel_size=4, stride=2, padding=1, batch_norm=True, dropout=False):\n","        super(DeconvBlock, self).__init__()\n","        self.deconv = torch.nn.ConvTranspose2d(input_size, output_size, kernel_size, stride, padding)\n","        self.bn = torch.nn.BatchNorm2d(output_size)\n","        self.drop = torch.nn.Dropout(0.5)\n","        self.relu = torch.nn.ReLU(True)\n","        self.batch_norm = batch_norm\n","        self.dropout = dropout\n","\n","    def forward(self, x):\n","        if self.batch_norm:\n","            out = self.bn(self.deconv(self.relu(x)))\n","        else:\n","            out = self.deconv(self.relu(x))\n","\n","        if self.dropout:\n","            return self.drop(out)\n","        else:\n","            return out\n","\n","\n","class Generator(torch.nn.Module):\n","    def __init__(self, input_dim, num_filter, output_dim):\n","        super(Generator, self).__init__()\n","\n","        # Encoder\n","        self.conv1 = ConvBlock(input_dim, num_filter, activation=False, batch_norm=False)\n","        self.conv2 = ConvBlock(num_filter, num_filter * 2)\n","        self.conv3 = ConvBlock(num_filter * 2, num_filter * 4)\n","        self.conv4 = ConvBlock(num_filter * 4, num_filter * 8)\n","        self.conv5 = ConvBlock(num_filter * 8, num_filter * 8)\n","        self.conv6 = ConvBlock(num_filter * 8, num_filter * 8)\n","        self.conv7 = ConvBlock(num_filter * 8, num_filter * 8)\n","        self.conv8 = ConvBlock(num_filter * 8, num_filter * 8, batch_norm=False)\n","        # Decoder\n","        self.deconv1 = DeconvBlock(num_filter * 8, num_filter * 8, dropout=True)\n","        self.deconv2 = DeconvBlock(num_filter * 8 * 2, num_filter * 8, dropout=True)\n","        self.deconv3 = DeconvBlock(num_filter * 8 * 2, num_filter * 8, dropout=True)\n","        self.deconv4 = DeconvBlock(num_filter * 8 * 2, num_filter * 8)\n","        self.deconv5 = DeconvBlock(num_filter * 8 * 2, num_filter * 4)\n","        self.deconv6 = DeconvBlock(num_filter * 4 * 2, num_filter * 2)\n","        self.deconv7 = DeconvBlock(num_filter * 2 * 2, num_filter)\n","        self.deconv8 = DeconvBlock(num_filter * 2, output_dim, batch_norm=False)\n","\n","    def forward(self, x):\n","        # Encoder\n","        enc1 = self.conv1(x)\n","        enc2 = self.conv2(enc1)\n","        enc3 = self.conv3(enc2)\n","        enc4 = self.conv4(enc3)\n","        enc5 = self.conv5(enc4)\n","        enc6 = self.conv6(enc5)\n","        enc7 = self.conv7(enc6)\n","        enc8 = self.conv8(enc7)\n","        # Decoder with skip-connections\n","        dec1 = self.deconv1(enc8)\n","        dec1 = torch.cat([dec1, enc7], 1)\n","        dec2 = self.deconv2(dec1)\n","        dec2 = torch.cat([dec2, enc6], 1)\n","        dec3 = self.deconv3(dec2)\n","        dec3 = torch.cat([dec3, enc5], 1)\n","        dec4 = self.deconv4(dec3)\n","        dec4 = torch.cat([dec4, enc4], 1)\n","        dec5 = self.deconv5(dec4)\n","        dec5 = torch.cat([dec5, enc3], 1)\n","        dec6 = self.deconv6(dec5)\n","        dec6 = torch.cat([dec6, enc2], 1)\n","        dec7 = self.deconv7(dec6)\n","        dec7 = torch.cat([dec7, enc1], 1)\n","        dec8 = self.deconv8(dec7)\n","        out = torch.nn.Tanh()(dec8)\n","        return out\n","\n","    def normal_weight_init(self, mean=0.0, std=0.02):\n","        for m in self.children():\n","            if isinstance(m, ConvBlock):\n","                torch.nn.init.normal(m.conv.weight, mean, std)\n","            if isinstance(m, DeconvBlock):\n","                torch.nn.init.normal(m.deconv.weight, mean, std)\n","\n","\n","class Discriminator(torch.nn.Module):\n","    def __init__(self, input_dim, num_filter, output_dim):\n","        super(Discriminator, self).__init__()\n","\n","        self.conv1 = ConvBlock(input_dim, num_filter, activation=False, batch_norm=False)\n","        self.conv2 = ConvBlock(num_filter, num_filter * 2)\n","        self.conv3 = ConvBlock(num_filter * 2, num_filter * 4)\n","        self.conv4 = ConvBlock(num_filter * 4, num_filter * 8, stride=1)\n","        self.conv5 = ConvBlock(num_filter * 8, output_dim, stride=1, batch_norm=False)\n","\n","    def forward(self, x, label):\n","        x = torch.cat([x, label], 1)\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = self.conv5(x)\n","        # GAN\n","        out = torch.nn.Sigmoid()(x)\n","        # WGAN\n","        # out = torch.nn.Linear(x.shape[2], 1).cuda()(x)\n","        return out\n","\n","    def normal_weight_init(self, mean=0.0, std=0.02):\n","        for m in self.children():\n","            if isinstance(m, ConvBlock):\n","                torch.nn.init.normal(m.conv.weight, mean, std)\n"],"metadata":{"id":"aQtnkt5M0vTi","executionInfo":{"status":"ok","timestamp":1673722066569,"user_tz":-120,"elapsed":385,"user":{"displayName":"Catalin","userId":"16988798672554540152"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Training"],"metadata":{"id":"NLAJa1zlnOBY"}},{"cell_type":"code","source":["import torch\n","from torchvision import transforms\n","from torch.autograd import Variable\n","import argparse\n","import os\n","\n","dataset = 'LOLDataset'\n","direction = 'AtoB'\n","batch_size = 8\n","ngf = 64 # number of filters in the generator\n","ndf = 64 # number of filters in the discriminator\n","input_size = 256\n","resize_scale = 286\n","crop_size = 256\n","fliplr = True\n","num_epochs = 200\n","lrG = 0.0002 # generator learning rate\n","lrD = 0.0002 # discriminator learning rate\n","\n","# parameters needed for WGAN\n","training_ratio = 5 # for each step how many times to train the discriminator\n","wclip = 0.01 # weight clipping for the discriminator to improve performance\n","\n","# optimizers values\n","lamb = 100\n","beta1 = 0.5\n","beta2 = 0.999\n","\n","# Directories for loading data and saving results\n","data_dir = 'drive/MyDrive/' + dataset + '/'\n","save_dir = dataset + '_results/'\n","model_dir = dataset + '_model/'\n","\n","if not os.path.exists(save_dir):\n","    os.mkdir(save_dir)\n","if not os.path.exists(model_dir):\n","    os.mkdir(model_dir)\n","\n","# Data pre-processing\n","transform = transforms.Compose([transforms.Resize(input_size),\n","                                transforms.ToTensor(),\n","                                transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n","\n","# Train data\n","train_data = DatasetFromFolder(data_dir, subfolder='train', direction=direction, transform=transform,\n","                               resize_scale=resize_scale, crop_size=crop_size, fliplr=fliplr)\n","train_data_loader = torch.utils.data.DataLoader(dataset=train_data,\n","                                                batch_size=batch_size,\n","                                                shuffle=True)\n","\n","# Test data\n","test_data = DatasetFromFolder(data_dir, subfolder='test', direction=direction, transform=transform)\n","test_data_loader = torch.utils.data.DataLoader(dataset=test_data,\n","                                               batch_size=batch_size,\n","                                               shuffle=False)\n","test_input, test_target = test_data_loader.__iter__().__next__()\n","\n","# Models\n","G = Generator(3, ngf, 3)\n","# Load G\n","# G.load_state_dict(torch.load(model_dir + 'generator_param.pkl'))\n","D = Discriminator(6, ndf, 1)\n","# Load D\n","# D.load_state_dict(torch.load(model_dir + 'discriminator_param.pkl'))\n","G.cuda()\n","D.cuda()\n","G.normal_weight_init(mean=0.0, std=0.02)\n","D.normal_weight_init(mean=0.0, std=0.02)\n","\n","# Loss functions\n","BCE_loss = torch.nn.BCELoss().cuda()\n","L1_loss = torch.nn.L1Loss().cuda()\n","\n","# Optimizers\n","#GAN\n","# G_optimizer = torch.optim.Adam(G.parameters(), lr=lrG, betas=(beta1, beta2))\n","# D_optimizer = torch.optim.Adam(D.parameters(), lr=lrD, betas=(beta1, beta2))\n","#WGAN\n","G_optimizer = torch.optim.RMSprop(G.parameters(), lr=lrG)\n","D_optimizer = torch.optim.RMSprop(D.parameters(), lr=lrD)\n","\n","D_avg_losses = []\n","G_avg_losses = []\n","\n","step = 0\n","for epoch in range(num_epochs):\n","    D_losses = []\n","    G_losses = []\n","\n","    # training\n","    for i, (input, target) in enumerate(train_data_loader):\n","\n","        for _ in range(training_ratio):\n","          # input & target image data\n","          x_ = Variable(input.cuda())\n","          y_ = Variable(target.cuda())\n","\n","          # Train discriminator with real data\n","          D_real_decision = D(x_, y_).squeeze()\n","          real_ = Variable(torch.ones(D_real_decision.size()).cuda())\n","          # GAN\n","          # D_real_loss = BCE_loss(D_real_decision, real_)\n","          # WGAN\n","          D_real_loss = - torch.mean(D_real_decision)\n","          \n","          gen_image = G(x_)\n","          # Train discriminator with fake data\n","          D_fake_decision = D(x_, gen_image).squeeze()\n","          # GAN\n","          # fake_ = Variable(torch.zeros(D_fake_decision.size()).cuda())\n","          # D_fake_loss = BCE_loss(D_fake_decision, fake_)\n","          # WGAN\n","          D_fake_loss = torch.mean(D_fake_decision)\n","\n","          # D Back propagation\n","          D_loss = D_fake_loss + D_real_loss\n","          D.zero_grad()\n","          D_loss.backward()\n","          D_optimizer.step()\n","          with torch.no_grad(): \n","            for param in D.parameters(): # apply weight clipping on D\n","                param.data.clamp_(-wclip, wclip)\n","\n","        # Train generator\n","        gen_image = G(x_)\n","        D_fake_decision = D(x_, gen_image).squeeze()\n","        G_fake_loss = BCE_loss(D_fake_decision, real_)\n","\n","        # L1 loss\n","        l1_loss = lamb * L1_loss(gen_image, y_)\n","\n","        # G Back propagation\n","        G_loss = G_fake_loss + l1_loss\n","        G.zero_grad()\n","        G_loss.backward()\n","        G_optimizer.step()\n","\n","        # loss values\n","        print(D_loss)\n","        D_losses.append(D_loss.item())\n","        G_losses.append(G_loss.item())\n","\n","        print('Epoch [%d/%d], Step [%d/%d], D_loss: %.4f, G_loss: %.4f'\n","              % (epoch+1, num_epochs, i+1, len(train_data_loader), D_loss.item(), G_loss.item()))\n","\n","    D_avg_loss = torch.mean(torch.FloatTensor(D_losses))\n","    G_avg_loss = torch.mean(torch.FloatTensor(G_losses))\n","\n","    # avg loss values for plot\n","    D_avg_losses.append(D_avg_loss)\n","    G_avg_losses.append(G_avg_loss)\n","\n","    # Show result for test image\n","    gen_image = G(Variable(test_input.cuda()))\n","    gen_image = gen_image.cpu().data\n","    plot_test_result(test_input, test_target, gen_image, epoch, save=True, save_dir=save_dir)\n","\n","# Plot average losses\n","plot_loss(D_avg_losses, G_avg_losses, num_epochs, save=True, save_dir=save_dir)\n","\n","# Save trained parameters of model\n","torch.save(G.state_dict(), model_dir + 'generator_param.pkl')\n","torch.save(D.state_dict(), model_dir + 'discriminator_param.pkl')"],"metadata":{"id":"2nhMwA2S0-OT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Code block used when forcefully stopping training above\n","\n","# Plot average losses\n","plot_loss(D_avg_losses, G_avg_losses, num_epochs, save=True, save_dir=save_dir)\n","\n","# Save trained parameters of model\n","torch.save(G.state_dict(), model_dir + 'generator_param.pkl')\n","torch.save(D.state_dict(), model_dir + 'discriminator_param.pkl')"],"metadata":{"id":"PFLJ8WnuIg4Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Model validation"],"metadata":{"id":"eR2-1ItTnLXX"}},{"cell_type":"code","source":["# Model validation\n","import torch\n","from torchvision import transforms\n","from torch.autograd import Variable\n","import os\n","from math import log10, sqrt\n","\n","data_dir = 'drive/MyDrive/' + dataset + '/'\n","save_dir = dataset + '_val_results/'\n","model_dir = 'drive/MyDrive/' + dataset + '_model/'\n","\n","if not os.path.exists(save_dir):\n","    os.mkdir(save_dir)\n","if not os.path.exists(model_dir):\n","    os.mkdir(model_dir)\n","\n","# Data pre-processing\n","val_transform = transforms.Compose([transforms.Resize(input_size),\n","                                    transforms.ToTensor(),\n","                                    ])\n","\n","# Validation data\n","val_data = DatasetFromFolder(data_dir, subfolder='val', direction=direction, transform=val_transform)\n","val_data_loader = torch.utils.data.DataLoader(dataset=val_data,\n","                                               shuffle=False)\n","\n","# Load model\n","G = Generator(3, ngf, 3)\n","G.load_state_dict(torch.load(model_dir + 'generator_param.pkl'))\n","\n","def PSNR(original, compressed):\n","  mse = np.mean((original - compressed) ** 2)\n","  if(mse == 0):\n","    return 100\n","  max_pixel = 255.0\n","  psnr = 20 * log10(max_pixel / sqrt(mse))\n","  return psnr\n","\n","psnr_values = []\n","for i, (input, target) in enumerate(test_data_loader):\n","    # input & target image data\n","    x_ = Variable(input)\n","    y_ = Variable(target)\n","    gen_image = G(x_)\n","    psnr = PSNR(target.data.numpy(), gen_image.data.numpy())\n","    psnr_values.append(psnr)\n","    print(f'{i}: {psnr} psnr')\n","    gen_image = gen_image.data\n","\n","\n","    plot_test_result(input, target, gen_image, i, training=False, save=True, save_dir=save_dir)\n","    print('%d images are generated.' % (i + 1))\n","\n","print('PSNR mean: ' + str(np.mean(psnr_values)))"],"metadata":{"id":"CPYUOFj_IKbZ"},"execution_count":null,"outputs":[]}]}